# ðŸ§  Neural Network Project
## Overview
- This repository covers my implementations of Neural Networks on the MNIST dataset.
- The purpose of this repo is to document my learning journey as a student passionate about deep learning. Instead of just using pre-built tools, I focus on understanding the fundamentals â€” from forward pass and backpropagation to optimization and feature extraction.
- This is just the beginning, more experiments, architectures, and improvements will be added as I continue exploring neural networks.

## Projects in this Repo
1. Fully Connected Neural Network (MLP) [Brief overlook]
- Structure: Input â†’ Hidden Layers â†’ Output (Softmax).
- Implemented gradient descent and backpropagation from scratch.
- Helped me deeply understand how weights are updated, how activations flow, and the limitations of simple MLPs on image data.

2. Convolutional Neural Network (CNN)[Brief overlook]

- Uses convolution + pooling layers for feature extraction.
- Achieves much higher accuracy on handwritten digit recognition compared to the MLP.
- Showed me the power of CNNs in learning hierarchical representations and capturing spatial patterns.

## What Iâ€™ve Learned So Far
- How forward pass and backpropagation actually work.
- Why CNNs outperform basic networks on image data.
- The importance of optimizers, activation functions, and architecture design.
- That building models from scratch gives much stronger intuition than just relying on frameworks.

## Future Work
- Add experiments with different optimizers (Adam, RMSprop).
- Explore dropout, batch normalization, and regularization.
- Train on other datasets like FashionMNIST or CIFAR-10.
- Eventually scale to GANs and Vision Transformers (ViTs).
